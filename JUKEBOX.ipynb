{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JUKEBOX.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKFBYhVGDUPk"
      },
      "source": [
        "#BOOST GOOGLE COLAB MEMORY\n",
        "#i = []\n",
        "#while(True):\n",
        " #   i.append('a')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vN7LCpSEyDQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeiTfJl8GRbT",
        "outputId": "28696fa4-4644-4257-ee7f-c96b61d89926"
      },
      "source": [
        "#!nvidia-smi\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-7ecca9c3-a177-3d51-addd-302efa42c11b)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEphpfC9Cf_8"
      },
      "source": [
        "IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5vDyswcnS0t",
        "outputId": "4fa15692-8405-4113-cad1-bb9394c55dff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipkqru1vF2xC",
        "outputId": "51740a63-c3ae-4379-c782-52f17f3c67c3"
      },
      "source": [
        "!pip install git+https://github.com/openai/jukebox.git\n",
        "#!pip install jukebox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/jukebox.git\n",
            "  Cloning https://github.com/openai/jukebox.git to /tmp/pip-req-build-5i9eq9ok\n",
            "  Running command git clone -q https://github.com/openai/jukebox.git /tmp/pip-req-build-5i9eq9ok\n",
            "Collecting fire==0.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/b7/205702f348aab198baecd1d8344a90748cb68f53bdcd1cc30cbc08e47d3e/fire-0.1.3.tar.gz\n",
            "Collecting tqdm==4.45.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[?25hCollecting soundfile==0.10.3.post1\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Collecting unidecode==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba==0.48.0 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (0.48.0)\n",
            "Collecting librosa==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 60.4MB/s \n",
            "\u001b[?25hCollecting mpi4py>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/8f/bbd8de5ba566dd77e408d8136e2bab7fdf2b97ce06cab830ba8b50a2f588/mpi4py-3.0.3.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire==0.1.3->jukebox==1.0) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile==0.10.3.post1->jukebox==1.0) (1.14.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba==0.48.0->jukebox==1.0) (1.18.5)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.48.0->jukebox==1.0) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48.0->jukebox==1.0) (50.3.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (2.1.9)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.17.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->jukebox==1.0) (2.20)\n",
            "Building wheels for collected packages: jukebox, fire, librosa, mpi4py\n",
            "  Building wheel for jukebox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jukebox: filename=jukebox-1.0-cp36-none-any.whl size=197907 sha256=17728cf470d766ceb0e5449eaf366bffd2f514ec06e72867a576ca9cacb97300\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_mmporh7/wheels/bd/b6/f9/ad38a67dd989a522bbe6677e95efbc4607cdcf71e7249485fe\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.1.3-py2.py3-none-any.whl size=49706 sha256=9ef18fb0082c1df5bfd21dfce8680ccbd63e07c217946e974351dfdc6a01fad9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/1a/4d/6b30377c3051e76559d1185c1dbbfff15aed31f87acdd14c22\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=3bd13c9147601513d3c3f66664080f604cb620434eac27edadcb853191675e57\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
            "  Building wheel for mpi4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.0.3-cp36-cp36m-linux_x86_64.whl size=2074488 sha256=99ceb0d3fe838f4f15311eb5d4945458c17ff8f9bc815144f357d4d9d121cb58\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/e0/86/2b713dd512199096012ceca61429e12b960888de59818871d6\n",
            "Successfully built jukebox fire librosa mpi4py\n",
            "Installing collected packages: fire, tqdm, soundfile, unidecode, librosa, mpi4py, jukebox\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: librosa 0.6.3\n",
            "    Uninstalling librosa-0.6.3:\n",
            "      Successfully uninstalled librosa-0.6.3\n",
            "Successfully installed fire-0.1.3 jukebox-1.0 librosa-0.7.2 mpi4py-3.0.3 soundfile-0.10.3.post1 tqdm-4.45.0 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tulonOiHGS2R",
        "outputId": "82417a0e-c75f-4ffb-e250-370e07053a1d"
      },
      "source": [
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82rmo8jq9TYC"
      },
      "source": [
        "MODEL INIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65aR2OZxmfzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9329dd8f-c3bd-4ea6-f42d-13e7c3ba79e7"
      },
      "source": [
        "model = '1b_lyrics' # or '5b' or '1b_lyrics'\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = 3 if model in ('5b', '5b_lyrics') else 8\n",
        "# Specifies the directory to save the sample in.\n",
        "# We set this to the Google Drive mount point.\n",
        "hps.name = '/content/drive/MyDrive/MUSIC/JUKEBOX'\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = [.5,.5,.125]\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/vqvae.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Creating cond. autoregress with prior bins [79, 2048], \n",
            "dims [384, 6144], \n",
            "shift [ 0 79]\n",
            "input shape 6528\n",
            "input bins 2127\n",
            "Self copy is False\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v3_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v3_genre_ids.txt\n",
            "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:786432\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/1b_lyrics/prior_level_2.pth.tar https://openaipublic.azureedge.net/jukebox/models/1b_lyrics/prior_level_2.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/1b_lyrics/prior_level_2.pth.tar\n",
            "0: Loading prior in eval mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRtaP-9R_Tkb"
      },
      "source": [
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = 'primed'\n",
        "codes_file=None\n",
        "# Specify an audio file here.\n",
        "audio_file = '/content/drive/MyDrive/MUSIC/Solo/NEW_MUSIC_SHOWCASE/WWW.wav'\n",
        "# Specify how many seconds of audio to prime on.\n",
        "prompt_length_in_seconds=12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gJjaZ5VHpu_"
      },
      "source": [
        "CHECKPOINT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4MDpgOA_6Br"
      },
      "source": [
        "#CHECKPOINT FOR MODEL ONLY\n",
        "#if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  #for level in [1, 2]:\n",
        "   # data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "   # if os.path.isfile(data):\n",
        "    #  mode = 'upsample'\n",
        "    #  codes_file = data\n",
        "    #  print('Upsampling from level '+str(level))\n",
        "    #  break\n",
        "#print('mode is now '+mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Zh9DVYHscV"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlXxq5jKAEez"
      },
      "source": [
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia3reEFrrHbl"
      },
      "source": [
        "#NA?\n",
        "sample_length_in_seconds = 50\n",
        "\n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA3wFNnMrUD7"
      },
      "source": [
        "metas = [dict(artist = \"Kanye West\",\n",
        "            genre = \"Hip Hop\",\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = \"\"\"In the valley of design,\n",
        "            Designer for all the highs\n",
        "            Lows full of the pain\n",
        "            The story of you and I\n",
        "            Snakes want me close\n",
        "            Venom dripping like water\n",
        "            I was born in the jungle\n",
        "            Move froggy and you croak\n",
        "            \"\"\",\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx7KBmEZrdn7"
      },
      "source": [
        "sampling_temperature = .98\n",
        "\n",
        "lower_batch_size = 16\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "lower_level_chunk_size = 32\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqhugiJdCWp8"
      },
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLoopHFdB0Hb",
        "outputId": "04fe3ccf-52a4-4c55-93a3-69c865d592ba"
      },
      "source": [
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sampling level 2\n",
            "Sampling 6144 tokens for [0,6144]. Conditioning on 4134 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "142/142 [00:22<00:00,  6.27it/s]\n",
            "2010/2010 [03:00<00:00, 11.14it/s]\n",
            "Sampling 6144 tokens for [768,6912]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.12it/s]\n",
            "768/768 [01:08<00:00, 11.24it/s]\n",
            "Sampling 6144 tokens for [1536,7680]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.01it/s]\n",
            "768/768 [01:09<00:00, 11.04it/s]\n",
            "Sampling 6144 tokens for [2304,8448]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.07it/s]\n",
            "768/768 [01:08<00:00, 11.25it/s]\n",
            "Sampling 6144 tokens for [3072,9216]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.07it/s]\n",
            "768/768 [01:09<00:00, 11.12it/s]\n",
            "Sampling 6144 tokens for [3840,9984]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:30<00:00,  6.00it/s]\n",
            "768/768 [01:08<00:00, 11.15it/s]\n",
            "Sampling 6144 tokens for [4608,10752]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.04it/s]\n",
            "768/768 [01:10<00:00, 10.95it/s]\n",
            "Sampling 6144 tokens for [5376,11520]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.05it/s]\n",
            "768/768 [01:09<00:00, 10.99it/s]\n",
            "Sampling 6144 tokens for [6144,12288]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:30<00:00,  5.99it/s]\n",
            "768/768 [01:09<00:00, 11.11it/s]\n",
            "Sampling 6144 tokens for [6912,13056]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.11it/s]\n",
            "768/768 [01:09<00:00, 11.00it/s]\n",
            "Sampling 6144 tokens for [7680,13824]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.05it/s]\n",
            "768/768 [01:09<00:00, 11.03it/s]\n",
            "Sampling 6144 tokens for [8448,14592]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.09it/s]\n",
            "768/768 [01:10<00:00, 10.94it/s]\n",
            "Sampling 6144 tokens for [9216,15360]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.01it/s]\n",
            "768/768 [01:10<00:00, 10.92it/s]\n",
            "Sampling 6144 tokens for [9984,16128]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:30<00:00,  5.99it/s]\n",
            "768/768 [01:12<00:00, 10.56it/s]\n",
            "Sampling 6144 tokens for [10752,16896]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "180/180 [00:29<00:00,  6.03it/s]\n",
            "768/768 [01:11<00:00, 10.70it/s]\n",
            "Sampling 6144 tokens for [11082,17226]. Conditioning on 5814 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "194/194 [00:33<00:00,  5.82it/s]\n",
            "330/330 [00:31<00:00, 10.56it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IjRgH6CCSsc"
      },
      "source": [
        "UPSAMPLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLSt-reVCRoT",
        "outputId": "41955d20-3e70-429b-8127-a410a5a44dbd"
      },
      "source": [
        "# Set this False if you are on a local machine that has enough memory (this allows you to do the\n",
        "# lyrics alignment visualization during the upsampling stage). For a hosted runtime, \n",
        "# we'll need to go ahead and delete the top_prior if you are using the 5b_lyrics model.\n",
        "if True:\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conditioning on 1 above level(s)\n",
            "Checkpointing convs\n",
            "Checkpointing convs\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:0, Cond downsample:4, Raw to tokens:8, Sample length:65536\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/prior_level_0.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_0.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/prior_level_0.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Conditioning on 1 above level(s)\n",
            "Checkpointing convs\n",
            "Checkpointing convs\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:1, Cond downsample:4, Raw to tokens:32, Sample length:262144\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/prior_level_1.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_1.pth.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjUk4l6HC1Fq"
      },
      "source": [
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}